{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 假设我们要最小化函数  $y=x^2$, 选择初始点   $x_0=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 学习率为1的时候，x在5和-5之间震荡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 iteration(s): x1 is -5.000000.\n",
      "After 2 iteration(s): x2 is 5.000000.\n",
      "After 3 iteration(s): x3 is -5.000000.\n",
      "After 4 iteration(s): x4 is 5.000000.\n",
      "After 5 iteration(s): x5 is -5.000000.\n",
      "After 6 iteration(s): x6 is 5.000000.\n",
      "After 7 iteration(s): x7 is -5.000000.\n",
      "After 8 iteration(s): x8 is 5.000000.\n",
      "After 9 iteration(s): x9 is -5.000000.\n",
      "After 10 iteration(s): x10 is 5.000000.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "TRAINING_STEPS = 10\n",
    "LEARNING_RATE = 1\n",
    "x = tf.Variable(tf.constant(5, dtype=tf.float32), name=\"x\")\n",
    "y = tf.square(x)\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op)\n",
    "        x_value = sess.run(x)\n",
    "        print(\"After %s iteration(s): x%s is %f.\"% (i+1, i+1, x_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 学习率为0.001的时候，下降速度过慢，在901轮时才收敛到0.823355。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100 iteration(s): x100 is 4.092832.\n",
      "After 200 iteration(s): x200 is 3.350255.\n",
      "After 300 iteration(s): x300 is 2.742408.\n",
      "After 400 iteration(s): x400 is 2.244844.\n",
      "After 500 iteration(s): x500 is 1.837555.\n",
      "After 600 iteration(s): x600 is 1.504161.\n",
      "After 700 iteration(s): x700 is 1.231257.\n",
      "After 800 iteration(s): x800 is 1.007866.\n",
      "After 900 iteration(s): x900 is 0.825006.\n",
      "After 1000 iteration(s): x1000 is 0.675322.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_STEPS = 1000\n",
    "LEARNING_RATE = 0.001\n",
    "x = tf.Variable(tf.constant(5, dtype=tf.float32), name=\"x\")\n",
    "y = tf.square(x)\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op)\n",
    "        if i % 100 == 99: \n",
    "            x_value = sess.run(x)\n",
    "            print(\"After %s iteration(s): x%s is %f.\"% (i+1, i+1, x_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. 使用指数衰减的学习率，在迭代初期得到较高的下降速度，可以在较小的训练轮数下取得不错的收敛程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 10 iteration(s): x10 is 0.796464, learning rate is 0.066483.\n",
      "After 20 iteration(s): x20 is 0.244167, learning rate is 0.044200.\n",
      "After 30 iteration(s): x30 is 0.113049, learning rate is 0.029386.\n",
      "After 40 iteration(s): x40 is 0.068213, learning rate is 0.019537.\n",
      "After 50 iteration(s): x50 is 0.048895, learning rate is 0.012989.\n",
      "After 60 iteration(s): x60 is 0.039235, learning rate is 0.008635.\n",
      "After 70 iteration(s): x70 is 0.033913, learning rate is 0.005741.\n",
      "After 80 iteration(s): x80 is 0.030788, learning rate is 0.003817.\n",
      "After 90 iteration(s): x90 is 0.028874, learning rate is 0.002538.\n",
      "After 100 iteration(s): x100 is 0.027669, learning rate is 0.001687.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_STEPS = 100\n",
    "global_step = tf.Variable(0)\n",
    "LEARNING_RATE = tf.train.exponential_decay(0.1, global_step, 1, 0.96, staircase=True)\n",
    "\n",
    "x = tf.Variable(tf.constant(5, dtype=tf.float32), name=\"x\")\n",
    "y = tf.square(x)\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(y, global_step=global_step)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        sess.run(train_op)\n",
    "        if i % 10 == 9:\n",
    "            LEARNING_RATE_value = sess.run(LEARNING_RATE)\n",
    "            x_value = sess.run(x)\n",
    "            print(\"After %s iteration(s): x%s is %f, learning rate is %f.\"% (i+1, i+1, x_value, LEARNING_RATE_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
